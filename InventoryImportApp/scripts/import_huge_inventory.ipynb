{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f720ff5-61c5-4058-98bf-60d1f2444cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras as extras\n",
    "from psycopg2.extensions import AsIs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "\n",
    "run_py=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae80906-e05a-4742-8a63-33d0cba59cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_file=\"../Inventory_YIT_BlockChain2.xlsx\"\n",
    "error_file=\"../Error_Inventory.xlsx\"\n",
    "\n",
    "if run_py:\n",
    "    inventory_name=input(\"Enter Inventory Excel Fild(ex. Inventory_XYZ.xlsx) :\")\n",
    "    inventory_file=os.path.join(\"..\",inventory_name)\n",
    "    if  os.path.exists(inventory_file) : \n",
    "        \n",
    "     xname,xtype=os.path.splitext(inventory_name)\n",
    "     error_file=os.path.join(\"..\",f\"Error_{xname}{xtype}\")\n",
    "        \n",
    "        \n",
    "     print(f\"Inventory Path: {os.path.abspath(inventory_file)}\")\n",
    "     print(f\"Error Path (if errors): {os.path.abspath(error_file)} \")\n",
    "     \n",
    "     y_n = input(f\"Confirm import inventory ,please press y:\")\n",
    "     if y_n!='y':\n",
    "        exit()\n",
    "    \n",
    "    else:\n",
    "     print(f\"Not found excel file  {os.path.abspath(inventory_file)}\")   \n",
    "     exit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ddef08-4f40-4cea-8d79-8891c3be9789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eror case\n",
    "#inventory_file=\"inventory_import/Inventory_All-Error.xlsx\"\n",
    "#inventory_file=\"inventory_import/Inventory_Incomplete.xlsx\"\n",
    "\n",
    "# complter case\n",
    "#inventory_file=\"inventory_import/Inventory_Master.xlsx\"\n",
    "#inventory_file=\"inventory_import/Inventory_MEA_060622_2025.xlsx\"\n",
    "\n",
    "# get from database or file\n",
    "inventory_schema='InventoryExport_Schema.xlsx'\n",
    "\n",
    "no_records=1\n",
    "\n",
    "is_inccorect_data=False\n",
    "list_error=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a981ee0-c794-4c45-a351-97159df53f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f81936-6de3-48c0-8b4c-75101bf5b44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isnan(value):\n",
    "  try:\n",
    "      import math\n",
    "      return math.isnan(float(value))\n",
    "  except:\n",
    "      return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813b640d-7950-4509-b885-95844be3b36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MappingData:\n",
    "    disp_name: str\n",
    "    pk_id: int\n",
    "    search_name: str\n",
    "    sql_cmd: str\n",
    "    params: dict\n",
    "\n",
    "# remove it in production\n",
    "def get_postgres_conn():\n",
    " try:\n",
    "  config = dotenv_values(dotenv_path='.env')  \n",
    "  conn = psycopg2.connect(\n",
    "         database=config['DATABASES_NAME'], user=config['DATABASES_USER'],\n",
    "      password=config['DATABASES_PASSWORD'], host=config['DATABASES_HOST'],\n",
    "     )\n",
    "  return conn\n",
    "\n",
    " except Exception as error:\n",
    "  print(error)      \n",
    "  raise error\n",
    "    \n",
    "def list_data(sql,params,connection):\n",
    " df=None   \n",
    "\n",
    " with connection.cursor() as cursor:\n",
    "    # print(sql)\n",
    "    # print(params)    \n",
    "    \n",
    "    if params is None:\n",
    "       cursor.execute(sql)\n",
    "    else:\n",
    "       cursor.execute(sql,params) \n",
    "    \n",
    "    columns = [col[0] for col in cursor.description]\n",
    "    dataList = [dict(zip(columns, row)) for row in cursor.fetchall()]\n",
    "    df = pd.DataFrame(data=dataList) \n",
    " return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b01a8ad-27ea-4019-9beb-a8c4decff014",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"========================================================================\")\n",
    "print(\"Load inventory schema mapping between excel report and inventory table\")\n",
    "df_schema=pd.read_excel(inventory_schema)\n",
    "df_schema=df_schema.sort_values(by=['IsPK','IsNULL','DisplayName'],ascending=False)\n",
    "#print(df_schema)\n",
    "print(df_schema[['DisplayName','ColumnName']])\n",
    "\n",
    "metaDF_pk=df_schema.query('IsPK==1').set_index('ColumnName')\n",
    "metaDF_string=df_schema.query('IsString==1').set_index('ColumnName')\n",
    "metaDF_notNull=df_schema.query('IsNULL==0').set_index('ColumnName')\n",
    "\n",
    "\n",
    "# print(metaDF_pk)\n",
    "# print(metaDF_string)\n",
    "#print(metaDF_notNull)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebcd4d0-4a60-4d65-8631-430da9ce2555",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_cols_error_file=['serial_number','quantity','project_id'\n",
    "                      ,'customer_warranty_start','customer_warranty_end','customer_sla_id' \\\n",
    "                      ,'yit_warranty_start','yit_warranty_end','yit_sla_id'\n",
    "                      ,'product_warranty_start','product_warranty_end','product_sla_id'\n",
    "                      ,'product_type_id','brand_id','model_id','branch_id','datacenter_id'\\\n",
    "                      ,'customer_support_id','customer_pm_support_id','cm_serviceteam_id'\n",
    "                      ,'pm_serviceteam_id','cm_serviceteam_id','product_support_id','function_id'\n",
    "                      ,'install_date','eos_date'\n",
    "                     ]\n",
    "\n",
    "#main_cols_error_file\n",
    "second_cols_error_file=  [ x for x in df_schema['ColumnName'].tolist() if x not in  main_cols_error_file ]\n",
    "#second_cols_error_file\n",
    "main_cols_error_file.extend(second_cols_error_file)\n",
    "#main_cols_error_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a633f-a49d-490c-bf32-cf3c94c38715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "415aeae2-48c7-4b1e-9a69-088c49261add",
   "metadata": {},
   "source": [
    "# Load Excel Inventory and Check Data Format and Null Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b29fa9-2427-4f75-acfd-3672dffbad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"========================================================================\")\n",
    "print(\"Load excel report inventory to import\")\n",
    "\n",
    "try:\n",
    "    df_new=pd.read_excel(inventory_file)\n",
    "    df_new=df_new[df_schema['DisplayName'].tolist()]\n",
    "    print(df_new.head(10))\n",
    "#print(df_new.info())\n",
    "\n",
    "except Exception as ex:\n",
    "   error=f\"Some columns in excel doestn't match exactly with inventory schema\\n {str(ex)}\"\n",
    "   raise Exception(error)\n",
    "\n",
    "# # check# aolumne\n",
    "# a=list(df_new.columns)\n",
    "# b=list(df_schema['DisplayName'])\n",
    "# a_diff_b= list ( set(a)^set(b) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72cb2c6-c1b3-4054-a0f9-2a2dae3c8ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Check Data Format and Null Value\")\n",
    "print(\"========================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce7dd30-e85b-4c84-9b61-4029ca32b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check# no-recourd\n",
    "if df_new.shape[0]<=no_records :\n",
    "    list_error.append(f\"Number of inventory is less than {no_records}\")\n",
    "else:\n",
    "    print(f\"Number of inventory  is more than {no_records}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d62b2f0-f932-447c-b57a-3f656506fce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check# null\n",
    "null_cols=df_new[list(metaDF_notNull['DisplayName'])].isnull().sum()\n",
    "null_cols=null_cols[null_cols>0]\n",
    "if not null_cols.empty:\n",
    "   list_error.append(\"found empty value in some columns in excel file : \\n\"+null_cols[null_cols>0].to_string())\n",
    "else:\n",
    "   print(\"there is no null value in required columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5da33a5-5378-444f-ac3c-5540a11134a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check# convert datatime \n",
    "# df_new['Install Date']=pd.to_datetime (df_new['Install Date'],format='%d %b %Y')\n",
    "# df_new['EOS Date']=pd.to_datetime (df_new['EOS Date'],format='%d %b %Y')\n",
    "# don't convert to datetime straightforwardli in order to advoid havong some NaT value for None datetime\n",
    "\n",
    "def convert_datetime_string_format(item):\n",
    "  if isnan(item)==False:\n",
    "    try:\n",
    "      d_date =datetime.strptime(item, '%d %b %y')\n",
    "      d_str =d_date.strftime('%Y-%m-%d')\n",
    "      return   d_str\n",
    "    except Exception as ex:\n",
    "       raise ex    \n",
    "  return item  \n",
    "try:\n",
    "\n",
    "    df_new['Cust Warranty Start']=pd.to_datetime (df_new['Cust Warranty Start'],format='%d %b %Y')\n",
    "    df_new['Cust Warranty End']=pd.to_datetime (df_new['Cust Warranty End'],format='%d %b %Y')\n",
    "    df_new['Yit Warranty Start']=pd.to_datetime (df_new['Yit Warranty Start'],format='%d %b %Y')\n",
    "    df_new['Yit Warranty End']=pd.to_datetime (df_new['Yit Warranty End'],format='%d %b %Y')\n",
    "    df_new['Product Warranty Start']=pd.to_datetime (df_new['Product Warranty Start'],format='%d %b %Y')\n",
    "    df_new['Product Warranty End']=pd.to_datetime (df_new['Product Warranty End'],format='%d %b %Y')\n",
    "    \n",
    "    df_new['Install Date']=df_new['Install Date'].apply(convert_datetime_string_format)\n",
    "    df_new['EOS Date']=df_new['EOS Date'].apply(convert_datetime_string_format)\n",
    "\n",
    "except Exception as ex:\n",
    "   list_error.append(\"Wrong DateFormat : \\n\"+str(ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f84b7ea-6b50-40af-8d60-9b7e764497df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check# customer and product nae\n",
    "try:\n",
    "    df_new['Customer Support']=df_new['Customer Support'].apply( lambda x : (x.strip().split('|')[0]).strip() if (isnan(x)==False) else np.NaN )\n",
    "    df_new['Customer PM Support']=df_new['Customer PM Support'].apply( lambda x : (x.strip().split('|')[0]).strip() if (isnan(x)==False) else np.NaN )\n",
    "    df_new['Product Support']=df_new['Product Support'].apply( lambda x : (x.strip().split('|')[0]).strip() if (isnan(x)==False) else np.NaN )\n",
    "except Exception as ex:\n",
    "   list_error.append(str(ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf987de3-3770-49d2-acfb-0c95ef3b8ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check# numberic value\n",
    "try:\n",
    "    df_new['Storage Capacity']=df_new['Storage Capacity'].astype(float)\n",
    "    df_new['QTY']=pd.to_numeric(df_new['QTY'])\n",
    "except Exception as ex:\n",
    "    list_error.append(str(ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd53a0e-e35a-4505-b13f-e785e8e5a694",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (len(list_error)>0):\n",
    "    print(\"Found some errors as folows\")\n",
    "    for i in range(len(list_error)):\n",
    "     print(f\"{i+1} - {list_error[i]}\")\n",
    "    raise Exception(f'error as the the following above, check error in {inventory_file}')\n",
    "\n",
    "# return error report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a672f6f-777a-457a-879e-4621041e9fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thrown error to show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d76b2a-a5af-44a8-99cd-91afc653565f",
   "metadata": {},
   "source": [
    "# Starting Point to import excel to databae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1936c9c8-f1de-4786-8ed4-9e5440cfc856",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data is ready to import\")\n",
    "print(df_new.info())\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c96a8f-1ea6-42fc-b4bb-d853a51b43b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Load Extract Transform and Import to Database\")\n",
    "print(\"Findk pk from name of all master table\")\n",
    "print(\"========================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c85db4-01a9-459b-bffe-a1f6323ee87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_pk_id(item,meta,df_filter):\n",
    "    \n",
    "  value_name=item[meta.disp_name]\n",
    " \n",
    "  if isnan(value_name)==False:\n",
    "    if  type(value_name)==str:\n",
    "      value_name=value_name.strip()  \n",
    "    \n",
    "    x=df_filter.query(f'{meta.search_name}==@value_name')\n",
    "    \n",
    "    if len(x.index)==1:\n",
    "        return x.iloc[0]['id']\n",
    "    else:\n",
    "        return np.nan    \n",
    "        #return None\n",
    "  else:\n",
    "        #return None\n",
    "        return value_name\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4e30cb-1919-4610-9842-c547faaefd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pk(df_temp,pk_id,search,px,sql):\n",
    "    try:\n",
    "\n",
    "        info_x=metaDF_pk.loc[pk_id,:]\n",
    "        disp_name=info_x['DisplayName']\n",
    "        \n",
    "        list_pkID_toQuery=tuple(df_temp[disp_name].dropna().unique())\n",
    "        print(f\"{pk_id} of {list_pkID_toQuery}\")\n",
    "        \n",
    "        if len(list_pkID_toQuery)==0:\n",
    "            df_temp[pk_id]=None\n",
    "            return df_temp\n",
    "        else:\n",
    " \n",
    "            meta= MappingData( disp_name=disp_name,pk_id=pk_id,search_name=search,sql_cmd=sql,params={px:list_pkID_toQuery} )\n",
    "\n",
    "            df_filter=list_data(meta.sql_cmd,meta.params,get_postgres_conn())\n",
    "            if df_filter.empty==False:\n",
    "             print(\"Found pk id as the belows\")   \n",
    "             print(df_filter)\n",
    "             df_temp[meta.pk_id]=df_temp.apply(get_pk_id,axis=1,args=(meta,df_filter))\n",
    "            else:\n",
    "             print(f\"No found any pk id along with {list_pkID_toQuery}\")   \n",
    "             df_temp[meta.pk_id]=np.nan\n",
    "                \n",
    "\n",
    "            print(\"Extract PK Id from \"+disp_name)\n",
    "            print(\"==============Found PK============\")\n",
    "            print(df_temp[df_new[pk_id].notnull()][[pk_id,disp_name]] .head(10))\n",
    "            print(\"==============NotFound PK============\")\n",
    "            print(df_temp[df_new[pk_id].isnull()][[pk_id,disp_name]])\n",
    "            \n",
    "        return df_temp\n",
    "\n",
    "    except Exception as ex:\n",
    "        print( ex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f1b009-05fc-4e5a-a6fe-7cc90f451b3d",
   "metadata": {},
   "source": [
    "# Mapping PK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bee2545-5a2f-44c4-8eec-c2b25ce297f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_name='enq_id'\n",
    "s_param='enq_param'\n",
    "\n",
    "\n",
    "#df_new=\n",
    "find_pk(df_new,'project_id',s_name, s_param,f\"\"\" select {s_name} ,id from app_project where {s_name} in %({s_param})s \"\"\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c98166-7696-4c15-92bd-348a25af95e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_name='productype_name'\n",
    "s_param='productype_param'\n",
    "#df_new=\n",
    "find_pk(df_new,'product_type_id',s_name, s_param, \\\n",
    "               f\"\"\" select {s_name} ,id from app_product_type where {s_name} in %({s_param})s \"\"\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf4c2b1-39a9-4f87-bf4a-b8ebe261089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_name='customer_name'\n",
    "s_param='cust_param'\n",
    "df_new=find_pk(df_new,'customer_support_id',s_name, s_param,f\"\"\" select {s_name} ,id from app_customer where {s_name} in %({s_param})s \"\"\" )\n",
    "df_new=find_pk(df_new,'customer_pm_support_id',s_name, s_param,f\"\"\" select {s_name} ,id from app_customer where {s_name} in %({s_param})s \"\"\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42943a7-87ed-44b3-a27f-4171a3a48950",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_name='product_name'\n",
    "s_param='prod_param'\n",
    "df_new=find_pk(df_new,'product_support_id',s_name, s_param,f\"\"\" select {s_name} ,id from app_product where {s_name} in %({s_param})s \"\"\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ecb28f-2bfd-426e-85ae-0888c23b697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_name='brand_name'\n",
    "s_param='brand_param'\n",
    "df_new=find_pk(df_new,'brand_id',s_name, s_param, \\\n",
    "               f\"\"\" select {s_name} ,id from app_brand where {s_name} in %({s_param})s \"\"\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fca9987-8496-4511-9b9b-a39510cb3113",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_name='model_name'\n",
    "s_param='model_param'\n",
    "df_new=find_pk(df_new,'model_id',s_name, s_param, \\\n",
    "               f\"\"\" select {s_name} ,id from app_model where {s_name} in %({s_param})s \"\"\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e367b335-b501-4c96-a6ad-32a455a33e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_name='datacenter_name'\n",
    "s_param='datacenter_param'\n",
    "df_new=find_pk(df_new,'datacenter_id',s_name, s_param, \\\n",
    "               f\"\"\" select {s_name} ,id from app_datacenter where {s_name} in %({s_param})s \"\"\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d35871-a194-4017-a1c7-a7ed73115c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_name='branch_name'\n",
    "s_param='branch_param'\n",
    "df_new=find_pk(df_new,'branch_id',s_name, s_param, \\\n",
    "               f\"\"\" select {s_name} ,id from app_branch where {s_name} in %({s_param})s \"\"\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392a5f9b-3f98-4131-b5ed-5925c09e3843",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_name='function_name'\n",
    "s_param='function_param'\n",
    "df_new=find_pk(df_new,'function_id',s_name, s_param, \\\n",
    "               f\"\"\" select {s_name} ,id from app_function where {s_name} in %({s_param})s \"\"\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c07445-44b3-4b29-b020-8777adbd1176",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_name='function_name'\n",
    "s_param='function_param'\n",
    "df_new=find_pk(df_new,'function_id',s_name, s_param, \\\n",
    "               f\"\"\" select {s_name} ,id from app_function where {s_name} in %({s_param})s \"\"\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcce5d6d-abe5-42e6-a0e1-d169c6889f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_name='service_team_name'\n",
    "s_param='service_param'\n",
    "s_sql= f\"\"\" select {s_name} ,id from app_serviceteam where {s_name} in %({s_param})s \"\"\"\n",
    "df_new=find_pk(df_new,'cm_serviceteam_id',s_name, s_param, s_sql)\n",
    "df_new=find_pk(df_new,'pm_serviceteam_id',s_name, s_param, s_sql )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac7deb4-9d6d-4998-9df4-1106d60812a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_name='sla_name'\n",
    "s_param='sla_param'\n",
    "s_sql= f\"\"\" select {s_name} ,id from app_sla where {s_name} in %({s_param})s \"\"\"\n",
    "\n",
    "df_new=find_pk(df_new,'customer_sla_id',s_name, s_param, s_sql)\n",
    "df_new=find_pk(df_new,'yit_sla_id',s_name, s_param, s_sql )\n",
    "df_new=find_pk(df_new,'product_sla_id',s_name, s_param, s_sql )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5604a3-cc49-437a-820c-d1cf69ae0cbc",
   "metadata": {},
   "source": [
    "# Get data ready for saving into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22450d27-2acc-4a40-abdb-9904cffa38b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mapping columns to insert into Databse\")\n",
    "not_pk_cols= list(set(df_schema['DisplayName'].tolist()) - set(metaDF_pk['DisplayName'].tolist()))\n",
    "#not_pk_cols\n",
    "#print(disp_to_col)\n",
    "\n",
    "metaDF_notPKCols=df_schema.query('IsPK==0')\n",
    "#metaDF_notPKCols\n",
    "\n",
    "disp_to_col_notPKCols=  dict( zip( metaDF_notPKCols['DisplayName'].tolist(), metaDF_notPKCols['ColumnName'].tolist()))\n",
    "#disp_to_col_notPKCols\n",
    "\n",
    "df_new=df_new.rename(columns= disp_to_col_notPKCols)\n",
    "# df_new=df_new.where(pd.notnull(df_new), None)\n",
    "\n",
    "final_cols_to_db=metaDF_notPKCols['ColumnName'].tolist()+metaDF_pk.index.tolist()\n",
    "df_new=df_new[final_cols_to_db]\n",
    "\n",
    "df_new['is_dummy']=False\n",
    "df_new['updated_at']=datetime.now()\n",
    "\n",
    "\n",
    "\n",
    "df_cols=df_new.columns.tolist()\n",
    "sql_cols_schemm=\"SELECT column_name FROM information_schema.columns WHERE  table_name = 'app_inventory'\"\n",
    "listCols_InventoryTable= list_data(sql_cols_schemm ,None,get_postgres_conn())\n",
    "table_cols=listCols_InventoryTable['column_name'].tolist()\n",
    "\n",
    "diff_cols=list(set(table_cols) -set(df_cols))\n",
    "print(diff_cols)\n",
    "if len(diff_cols)==1 : # except id\n",
    "  print(\"Getting Ready to database\")\n",
    "\n",
    "print(f\"{len(df_new.index)} items are about to import to database.\")\n",
    "print(\"=======================Create tempID for filtering unqualified data===============================\")\n",
    "\n",
    "df_new=df_new.reset_index(drop=False)\n",
    "df_new=df_new.rename(columns={'index':'temp_id'})\n",
    "\n",
    "df_new.info()\n",
    "df_new\n",
    "#df_new.to_excel('new_inventory.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26b976f-c3f1-476c-a23e-f73985c6390c",
   "metadata": {},
   "source": [
    "# Check correct Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d5502c-1cf7-4dfd-a163-18b7b56dde60",
   "metadata": {},
   "source": [
    "# Check Dupplicate Row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a81e93-e6b8-4281-b7af-c3ebad4bef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Check dupplicated record in excel file\")\n",
    "chekc_dup_cols=df_new.columns.tolist()\n",
    "chekc_dup_cols.remove('temp_id')\n",
    "\n",
    "df_duplicatedRows = df_new[df_new.duplicated(subset=chekc_dup_cols,keep='first')][main_cols_error_file]\n",
    "\n",
    "if len(df_duplicatedRows.index)>0:\n",
    " is_inccorect_data=True\n",
    "\n",
    "df_duplicatedRows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b1b082-543e-44ff-bfc7-621cc4768c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=df_new.drop_duplicates(subset=chekc_dup_cols,keep='first')\n",
    "#df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6511a339-2787-4b3f-86a3-c75e7b3e5060",
   "metadata": {},
   "source": [
    "# Check  not found some pk_id values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22004781-c7ff-49ca-a420-ce6517b235e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"check  not found pk_id\")\n",
    "metaDF_pk_not_null=metaDF_pk=df_schema.query('IsPK==1 and IsNULL==0').set_index('ColumnName')\n",
    "pkNull_df = df_new[df_new[list(metaDF_pk_not_null.index)].isnull().any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81b2f69-8ed7-466c-80d6-92a49877263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkNullCols_sr=df_new[metaDF_pk_not_null.index.tolist()].isnull().sum()\n",
    "pkNullCols_sr=pkNullCols_sr[pkNullCols_sr>0]\n",
    "pkNullCols_sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c5fa1a-f96b-46ea-bf6c-103cbf000089",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(pkNull_df.index)>0:\n",
    " is_inccorect_data=True\n",
    " df_new=df_new.drop(pkNull_df['temp_id'].tolist(), axis=0)\n",
    " pkNull_df=pkNull_df[main_cols_error_file]\n",
    "   \n",
    "pkNull_df \n",
    "#df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf1c04c-c5ee-4fd1-84be-e8d6dd87c692",
   "metadata": {},
   "source": [
    "# Check existing row base on ENQ ID,productType ,serial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678e9337-c17d-4937-8323-b214e1311786",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Check existing row base on ENQ ID,productType ,serial\")\n",
    "def is_existing_row(sql,params,connection):\n",
    "    try:\n",
    "         with connection.cursor() as cursor:\n",
    "            cursor.execute(sql,params) \n",
    "            row = cursor.fetchone()\n",
    "            return  row[0]\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        raise error\n",
    "\n",
    "\n",
    "list_existing_rows=[]\n",
    "\n",
    "sql_existing_row=\"\"\"\n",
    "SELECT EXISTS(SELECT 1 FROM app_inventory\n",
    "WHERE  serial_number<>'-' \n",
    "and serial_number=%(serial_param)s\n",
    "and product_type_id=%(type_param)s \n",
    "and project_id = %(project_param)s \n",
    ")\n",
    "\"\"\"\n",
    "# SELECT EXISTS(SELECT 1 FROM app_inventory\n",
    "# WHERE  (serial_number<>'-' and serial_number='FFGL2206A0FS-TEST'\n",
    "# and  product_type_id=10 and  project_id = 23 ))\n",
    "\n",
    "# init_param = {\"serial_param\":'FFGL2206A0FS-TEST' ,\"type_param\":10,\"project_param\":213}\n",
    "# isExisting=is_existing_row(sql_existing_row,init_param,get_postgres_conn())\n",
    "# print(isExisting)\n",
    "\n",
    "for index,row in df_new.iterrows(): \n",
    " init_param = {\"serial_param\":row['serial_number'] ,\"type_param\":row['product_type_id'],\"project_param\":row['project_id']}\n",
    " isExisting=is_existing_row(sql_existing_row,init_param,get_postgres_conn())\n",
    " if isExisting:\n",
    "    list_existing_rows.append(row['temp_id'])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa138511-bc56-4e5f-907a-5633be9d6cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_existing=pd.DataFrame()\n",
    "if len(list_existing_rows)>0:\n",
    " df_existing=df_new.query(\"temp_id in @list_existing_rows\")\n",
    " df_new=df_new.drop(list_existing_rows, axis=0)\n",
    " df_existing= df_existing[main_cols_error_file]\n",
    " is_inccorect_data=True   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436897c5-df14-4f0b-ad8f-9f74c1fe7dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_existing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d06a3c-4cb6-4eee-a56a-2c50e6f1f1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258a614e-d00e-4937-9ace-0708a0584a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_trasns.to_excel(tran2s_path2,index=False)\n",
    "if is_inccorect_data:\n",
    "  writer=pd.ExcelWriter(error_file,engine='xlsxwriter')\n",
    "  if  not df_duplicatedRows.empty:\n",
    "    df_duplicatedRows.to_excel(writer, sheet_name=\"Dupplicated_Rows\",index=False)\n",
    "  if  not pkNull_df.empty:\n",
    "    pkNullCols_sr.to_excel(writer, sheet_name=\"NotFoundReferKey_Columns\")\n",
    "    pkNull_df.to_excel(writer, sheet_name=\"NotFoundReferKey_Rows\",index=False)\n",
    "  if  not df_existing.empty:\n",
    "    df_existing.to_excel(writer, sheet_name=\"Existing_Rows\",index=False)  \n",
    "  writer.save()\n",
    "else:\n",
    "   print(\"No any incomplete data\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4def44bc-f63d-4fea-8549-d2bf65bd0e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=df_new.reset_index(drop=True)\n",
    "df_new=df_new.drop(columns=['temp_id'])\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6729f33-fcd8-4444-a649-6057be8e7758",
   "metadata": {},
   "source": [
    "# Save to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078a5b10-5cad-4491-a123-72628ed507c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_to_null_float(f,\n",
    "        _NULL=psycopg2.extensions.AsIs('NULL'),\n",
    "        _Float=psycopg2.extensions.Float):\n",
    "    if not np.isnan(f):\n",
    "        return _Float(f)\n",
    "    return _NULL\n",
    "\n",
    "psycopg2.extensions.register_adapter(float, nan_to_null_float)\n",
    "\n",
    "def nan_to_null_int(f,\n",
    "        _NULL=psycopg2.extensions.AsIs('NULL'),\n",
    "        _Int=psycopg2.extensions.Int):\n",
    "    if not np.isnan(f):\n",
    "        return _Int(f)\n",
    "    return _NULL\n",
    "\n",
    "psycopg2.extensions.register_adapter(int, nan_to_null_int)\n",
    "\n",
    "def add_data_values(df, table,conn):\n",
    "    \"\"\"\n",
    "    Using psycopg2.extras.execute_values() to insert the dataframe\n",
    "    \"\"\"\n",
    "    # Create a list of tupples from the dataframe values\n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    # Comma-separated dataframe columns\n",
    "    cols = ','.join(list(df.columns))\n",
    "    # SQL quert to execute\n",
    "    query  = \"INSERT INTO %s(%s) VALUES %%s\" % (table, cols)\n",
    "    #print(query)\n",
    "    #return query,tuples\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        extras.execute_values(cursor, query, tuples)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        raise error\n",
    "        return 0\n",
    "    \n",
    "    return 1\n",
    "    cursor.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5d25dd-0622-47cb-992d-3b7ef4471cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_new.empty==False: \n",
    "    result=add_data_values(df_new,'app_inventory',get_postgres_conn())\n",
    "    if  result==1:\n",
    "        print(f\"{len(df_new.index)} items have been imported to database successfully.\")\n",
    "        print(\"importing data succeeded\")\n",
    "else:\n",
    "    print(\"Error\")\n",
    "    print(\"No new inventory to import\")\n",
    "    print(\"All item exists in  inventory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfbdeba-692e-4fae-b53c-5b6636a13dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_inccorect_data==False:\n",
    "    os.remove(inventory_file)\n",
    "    print(f\"Import successfully so {os.path.abspath(inventory_file)} was deleted.\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Cannot import some inventories into database\")\n",
    "    print(f\"check error file in {os.path.abspath(error_file)} compare to {os.path.abspath(inventory_file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559a7ca3-aff5-4ca7-a12a-16b14a6203c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "\n",
    "# sql_cols_test=\"SELECT column_name FROM information_schema.columns WHERE  table_name   = 'test_inventoy'\"\n",
    "# listCols_TestTable= list_data(sql_cols_test ,None,get_postgres_conn())\n",
    "# listCols_TestTable=listCols_TestTable['column_name'].tolist()\n",
    "# listCols_TestTable.remove('id')\n",
    "# print(listCols_TestTable)\n",
    "# df_test=df_new[listCols_TestTable]\n",
    "# df_test\n",
    "\n",
    "# add_data_values(df_test,'test_inventoy',get_postgres_conn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6ca912-fca6-403b-a8e6-eef46c67f186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65014a90-f1b9-4076-b93c-4509b747598d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a57a09b-0bdf-4679-b423-3f037f0f9946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
